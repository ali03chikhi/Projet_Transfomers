{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "from pathlib import Path\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚è≥ Installation de PyTorch (version CUDA)...\n",
            "Note: you may need to restart the kernel to use updated packages.Looking in indexes: https://download.pytorch.org/whl/cu122\n",
            "\n",
            "‚è≥ Installation des outils d'image...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
            "ERROR: No matching distribution found for torch\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (11.1.0)\n",
            "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (2.1.3)\n",
            "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
            "   ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 11.3/39.0 MB 72.2 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 34.9/39.0 MB 97.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 39.0/39.0 MB 79.7 MB/s eta 0:00:00\n",
            "Installing collected packages: opencv-python\n",
            "Successfully installed opencv-python-4.12.0.88\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚è≥ Installation de Transformers et Hugging Face...\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-1.1.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting peft\n",
            "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub) (4.12.2)\n",
            "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from peft) (5.9.0)\n",
            "Collecting torch>=1.13.0 (from peft)\n",
            "  Downloading torch-2.9.1-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft) (72.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.6.15)\n",
            "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
            "   ---------------------------------------  11.8/12.0 MB 79.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 12.0/12.0 MB 62.0 MB/s eta 0:00:00\n",
            "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
            "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
            "   --------------------------------------- 566.1/566.1 kB 35.1 MB/s eta 0:00:00\n",
            "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
            "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.7/2.7 MB 70.1 MB/s eta 0:00:00\n",
            "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
            "   ---------------------------------------- 0.0/556.4 kB ? eta -:--:--\n",
            "   --------------------------------------- 556.4/556.4 kB 36.2 MB/s eta 0:00:00\n",
            "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
            "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
            "Downloading torch-2.9.1-cp313-cp313-win_amd64.whl (110.9 MB)\n",
            "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/110.9 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 6.6/110.9 MB 38.2 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 29.9/110.9 MB 77.9 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 53.0/110.9 MB 89.6 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 76.0/110.9 MB 95.1 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 98.0/110.9 MB 96.6 MB/s eta 0:00:01\n",
            "   --------------------------------------  110.9/110.9 MB 98.6 MB/s eta 0:00:01\n",
            "   --------------------------------------- 110.9/110.9 MB 82.5 MB/s eta 0:00:00\n",
            "Installing collected packages: safetensors, torch, huggingface-hub, tokenizers, accelerate, transformers, peft\n",
            "\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----- ---------------------------------- 1/7 [torch]\n",
            "   ----------- ---------------------------- 2/7 [huggingface-hub]\n",
            "   ----------- ---------------------------- 2/7 [huggingface-hub]\n",
            "   ----------- ---------------------------- 2/7 [huggingface-hub]\n",
            "   ----------- ---------------------------- 2/7 [huggingface-hub]\n",
            "   ----------- ---------------------------- 2/7 [huggingface-hub]\n",
            "   ----------------- ---------------------- 3/7 [tokenizers]\n",
            "   ---------------------- ----------------- 4/7 [accelerate]\n",
            "   ---------------------- ----------------- 4/7 [accelerate]\n",
            "   ---------------------- ----------------- 4/7 [accelerate]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------- ----------- 5/7 [transformers]\n",
            "   ---------------------------------- ----- 6/7 [peft]\n",
            "   ---------------------------------- ----- 6/7 [peft]\n",
            "   ---------------------------------- ----- 6/7 [peft]\n",
            "   ---------------------------------- ----- 6/7 [peft]\n",
            "   ---------------------------------- ----- 6/7 [peft]\n",
            "   ---------------------------------- ----- 6/7 [peft]\n",
            "   ---------------------------------------- 7/7 [peft]\n",
            "\n",
            "Successfully installed accelerate-1.11.0 huggingface-hub-0.36.0 peft-0.18.0 safetensors-0.6.2 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "‚úÖ Installation termin√©e. VEUILLEZ RED√âMARRER LE KERNEL.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\abchikhi\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The scripts hf.exe, huggingface-cli.exe and tiny-agents.exe are installed in 'C:\\Users\\abchikhi\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'C:\\Users\\abchikhi\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The scripts transformers-cli.exe and transformers.exe are installed in 'C:\\Users\\abchikhi\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
          ]
        }
      ],
      "source": [
        "# On utilise %pip pour cibler le bon environnement Python\n",
        "# On ajoute --user pour √©viter l'erreur \"Acc√®s refus√©\"\n",
        "\n",
        "print(\"‚è≥ Installation de PyTorch (version CUDA)...\")\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu122 --user\n",
        "\n",
        "print(\"‚è≥ Installation des outils d'image...\")\n",
        "%pip install opencv-python pillow numpy matplotlib tqdm --user\n",
        "\n",
        "print(\"‚è≥ Installation de Transformers et Hugging Face...\")\n",
        "%pip install transformers huggingface-hub peft accelerate --user\n",
        "\n",
        "print(\"‚úÖ Installation termin√©e. VEUILLEZ RED√âMARRER LE KERNEL.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Import r√©ussi !\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
        "print(\"‚úÖ Import r√©ussi !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1xn7dUHNYD9",
        "outputId": "77c4726d-2f5e-436a-a61f-553c0d07b149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "DETAILED CHANNEL ANALYSIS\n",
            "==================================================\n",
            "\n",
            "Channel 0:\n",
            "  Valid values: 1627140 (69.75%)\n",
            "  NaN values: 705660 (30.25%)\n",
            "  Min (ignoring NaN): -1269.60\n",
            "  Max (ignoring NaN): 804.97\n",
            "  Mean (ignoring NaN): -86.09\n",
            "\n",
            "Channel 1:\n",
            "  Valid values: 1627140 (69.75%)\n",
            "  NaN values: 705660 (30.25%)\n",
            "  Min (ignoring NaN): -615.58\n",
            "  Max (ignoring NaN): 670.23\n",
            "  Mean (ignoring NaN): 56.33\n",
            "\n",
            "Channel 2:\n",
            "  Valid values: 1627140 (69.75%)\n",
            "  NaN values: 705660 (30.25%)\n",
            "  Min (ignoring NaN): 1310.65\n",
            "  Max (ignoring NaN): 2961.60\n",
            "  Mean (ignoring NaN): 1755.40\n",
            "\n",
            "==================================================\n",
            "OVERALL STATISTICS\n",
            "==================================================\n",
            "Total pixels: 2332800\n",
            "Pixels with at least one valid value: 1627140 (69.8%)\n",
            "Total values (across 3 channels): 6998400\n",
            "Total valid values: 4881420\n",
            "\n",
            "==================================================\n",
            "SEARCHING FOR VALID DATA...\n",
            "==================================================\n",
            "Found 1627140 pixels with valid data!\n",
            "\n",
            "First 3 valid pixels:\n",
            "  Position (31, 6): [-734.60004 -425.95316 1340.2417 ]\n",
            "  Position (31, 7): [-728.9061  -423.09607 1335.3439 ]\n",
            "  Position (31, 9): [-725.3841  -421.93024 1331.5236 ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"DETAILED CHANNEL ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check each channel separately\n",
        "for i in range(3):\n",
        "    channel = depth_data[:, :, i]\n",
        "    valid_count = (~np.isnan(channel)).sum()\n",
        "    nan_count = np.isnan(channel).sum()\n",
        "\n",
        "    print(f\"\\nChannel {i}:\")\n",
        "    print(f\"  Valid values: {valid_count} ({valid_count / channel.size * 100:.2f}%)\")\n",
        "    print(f\"  NaN values: {nan_count} ({nan_count / channel.size * 100:.2f}%)\")\n",
        "\n",
        "    if valid_count > 0:\n",
        "        print(f\"  Min (ignoring NaN): {np.nanmin(channel):.2f}\")\n",
        "        print(f\"  Max (ignoring NaN): {np.nanmax(channel):.2f}\")\n",
        "        print(f\"  Mean (ignoring NaN): {np.nanmean(channel):.2f}\")\n",
        "\n",
        "# Overall statistics\n",
        "total_pixels = depth_data.shape[0] * depth_data.shape[1]\n",
        "total_values = depth_data.size\n",
        "valid_pixels_count = (~np.isnan(depth_data)).any(axis=2).sum()\n",
        "\n",
        "print(f\"\\n{'=' * 50}\")\n",
        "print(\"OVERALL STATISTICS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total pixels: {total_pixels}\")\n",
        "print(f\"Pixels with at least one valid value: {valid_pixels_count} ({valid_pixels_count/total_pixels*100:.1f}%)\")\n",
        "print(f\"Total values (across 3 channels): {total_values}\")\n",
        "print(f\"Total valid values: {(~np.isnan(depth_data)).sum()}\")\n",
        "\n",
        "# Try to find and display some valid values if they exist\n",
        "print(f\"\\n{'=' * 50}\")\n",
        "print(\"SEARCHING FOR VALID DATA...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "valid_mask = ~np.isnan(depth_data)\n",
        "if valid_mask.any():\n",
        "    # Find pixels with valid data\n",
        "    valid_pixels = np.any(valid_mask, axis=2)\n",
        "    valid_coords = np.argwhere(valid_pixels)\n",
        "\n",
        "    if len(valid_coords) > 0:\n",
        "        print(f\"Found {len(valid_coords)} pixels with valid data!\")\n",
        "        print(f\"\\nFirst 3 valid pixels:\")\n",
        "        for idx in valid_coords[:3]:\n",
        "            y, x = idx\n",
        "            print(f\"  Position ({y}, {x}): {depth_data[y, x]}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  WARNING: NO VALID DATA FOUND IN ENTIRE FILE!\")\n",
        "    print(\"\\nPossible issues:\")\n",
        "    print(\"  1. File is corrupted\")\n",
        "    print(\"  2. Wrong file exported from Zivid\")\n",
        "    print(\"  3. Data needs special loading procedure\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmdTUqEFODAa"
      },
      "source": [
        "Preparation de l'env\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-pCSGEFMREbk"
      },
      "outputs": [],
      "source": [
        "def load_pretrained_model(model_name=\"depth-anything/Depth-Anything-V2-Small-hf\"):\n",
        "    \"\"\"\n",
        "    Charge le mod√®le Depth Anything V2 pr√©-entra√Æn√© et son processeur d'images\n",
        "    \"\"\"\n",
        "    print(f\"üì• Chargement du mod√®le: {model_name}\")\n",
        "\n",
        "    image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "    base_model = AutoModelForDepthEstimation.from_pretrained(model_name)\n",
        "\n",
        "    print(f\"‚úÖ Mod√®le charg√© avec succ√®s\")\n",
        "    return base_model, image_processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "1e58d3730b684917b3be89d38cd28ed7",
            "48fed41b86484cc69e97afd7201b3f1d",
            "836a5991140b4555af8547aff5249c35",
            "fb78ae1d82fa4cb491d18cb4deb7c1df",
            "7734292198df4e0e9800bccaa2df8fa6",
            "7f848dfbe32b4328a8995eae51747ef5",
            "ee145691058c46708dd70c8e82c4659b",
            "92c720ebd5d340d18a85951dbd0caa26",
            "607f56a23c4a4d258a44568d80d8b6e0",
            "86e1b9eba1ce40c789fee7d975e6d808",
            "4e5148adce63409bad335d560b48c469",
            "ee3e596dd0bc409eb1881ae126249055",
            "c8c7361241d642aba28db4583568a43d",
            "6a2beca0ae69432290746120f97d8d9d",
            "076e2ab7dedf4ed8b75a60f1f3a4c182",
            "85960be4e08a418daff7764b81cfc1a5",
            "157d607e7a5d4ddd9ba3d89812e33617",
            "5aa91a828b5d457b86a960116ee87ccf",
            "70f8d58533414a13b0d24e5baf4d801b",
            "7300f79f002b45a59b181c4f3b89b604",
            "2a2389a8e9474a1c954fea1ef57ff827",
            "309e815f91bf4a5e903514e9ae19cf4b",
            "dc130e6335c0479c9a14f58346264929",
            "22ba49dd0e2d44ab87ca48ba3c1c2694",
            "5ffa3f78d94940a09d39d879db31afa0",
            "18f42814e26745dbbfdbe1ac5cf57298",
            "71dd44e393084109951e526ddae89efb",
            "cef818123e294b4bbeb1a0b02fa9165d",
            "26a5af69e89f449abf359097bd213a83",
            "383b0a4ac06f44a8a02dea81a6eb8967",
            "0c6eba7aa7de4611b9176572cb53b7fe",
            "63377198212c4fab8098723b7cd6915d",
            "8233d752f5e54588b9f565c34d1efd24"
          ]
        },
        "id": "tm4gWh0oR9og",
        "outputId": "dea719a9-c15f-449f-87ec-1d6e20199182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì• Chargement du mod√®le: depth-anything/Depth-Anything-V2-Small-hf\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "929feb93e4624b14af3b6bd5dc98b3db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\abchikhi\\AppData\\Roaming\\Python\\Python313\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abchikhi\\.cache\\huggingface\\hub\\models--depth-anything--Depth-Anything-V2-Small-hf. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "823c7fd887da46ce9f78da66d84d81a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/950 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00eec56582164404a0fdcfb740c05960",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/99.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Mod√®le charg√© avec succ√®s\n"
          ]
        }
      ],
      "source": [
        "base_model, image_processor = load_pretrained_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D0KEQcWmSRtZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "base_model = base_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESvNSUCKT-wz",
        "outputId": "384a2893-2cf8-40d3-c0c7-354813d703d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Total parameters: 24,785,089\n",
            "üìä Trainable parameters: 24,785,089\n"
          ]
        }
      ],
      "source": [
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in base_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in base_model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"üìä Total parameters: {total_params:,}\")\n",
        "print(f\"üìä Trainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g10AY5Rejk6",
        "outputId": "142e817e-3fd4-46d8-8586-9385fbef7af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Inspecting model architecture...\n",
            "\n",
            "============================================================\n",
            "MODEL STRUCTURE:\n",
            "  : DepthAnythingForDepthEstimation\n",
            "  backbone: Dinov2Backbone\n",
            "  backbone.embeddings: Dinov2Embeddings\n",
            "  backbone.embeddings.patch_embeddings: Dinov2PatchEmbeddings\n",
            "  backbone.embeddings.patch_embeddings.projection: Conv2d\n",
            "  backbone.embeddings.dropout: Dropout\n",
            "  backbone.encoder: Dinov2Encoder\n",
            "  backbone.encoder.layer: ModuleList\n",
            "  backbone.encoder.layer.0: Dinov2Layer\n",
            "  backbone.encoder.layer.0.norm1: LayerNorm\n",
            "  backbone.encoder.layer.0.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.0.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.0.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.0.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.0.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.0.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.0.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.0.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.0.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.0.drop_path: Identity\n",
            "  backbone.encoder.layer.0.norm2: LayerNorm\n",
            "  backbone.encoder.layer.0.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.0.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.0.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.0.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.0.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.1: Dinov2Layer\n",
            "  backbone.encoder.layer.1.norm1: LayerNorm\n",
            "  backbone.encoder.layer.1.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.1.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.1.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.1.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.1.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.1.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.1.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.1.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.1.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.1.drop_path: Identity\n",
            "  backbone.encoder.layer.1.norm2: LayerNorm\n",
            "  backbone.encoder.layer.1.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.1.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.1.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.1.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.1.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.2: Dinov2Layer\n",
            "  backbone.encoder.layer.2.norm1: LayerNorm\n",
            "  backbone.encoder.layer.2.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.2.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.2.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.2.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.2.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.2.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.2.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.2.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.2.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.2.drop_path: Identity\n",
            "  backbone.encoder.layer.2.norm2: LayerNorm\n",
            "  backbone.encoder.layer.2.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.2.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.2.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.2.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.2.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.3: Dinov2Layer\n",
            "  backbone.encoder.layer.3.norm1: LayerNorm\n",
            "  backbone.encoder.layer.3.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.3.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.3.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.3.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.3.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.3.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.3.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.3.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.3.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.3.drop_path: Identity\n",
            "  backbone.encoder.layer.3.norm2: LayerNorm\n",
            "  backbone.encoder.layer.3.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.3.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.3.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.3.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.3.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.4: Dinov2Layer\n",
            "  backbone.encoder.layer.4.norm1: LayerNorm\n",
            "  backbone.encoder.layer.4.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.4.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.4.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.4.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.4.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.4.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.4.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.4.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.4.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.4.drop_path: Identity\n",
            "  backbone.encoder.layer.4.norm2: LayerNorm\n",
            "  backbone.encoder.layer.4.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.4.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.4.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.4.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.4.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.5: Dinov2Layer\n",
            "  backbone.encoder.layer.5.norm1: LayerNorm\n",
            "  backbone.encoder.layer.5.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.5.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.5.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.5.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.5.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.5.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.5.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.5.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.5.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.5.drop_path: Identity\n",
            "  backbone.encoder.layer.5.norm2: LayerNorm\n",
            "  backbone.encoder.layer.5.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.5.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.5.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.5.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.5.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.6: Dinov2Layer\n",
            "  backbone.encoder.layer.6.norm1: LayerNorm\n",
            "  backbone.encoder.layer.6.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.6.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.6.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.6.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.6.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.6.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.6.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.6.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.6.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.6.drop_path: Identity\n",
            "  backbone.encoder.layer.6.norm2: LayerNorm\n",
            "  backbone.encoder.layer.6.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.6.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.6.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.6.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.6.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.7: Dinov2Layer\n",
            "  backbone.encoder.layer.7.norm1: LayerNorm\n",
            "  backbone.encoder.layer.7.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.7.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.7.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.7.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.7.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.7.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.7.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.7.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.7.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.7.drop_path: Identity\n",
            "  backbone.encoder.layer.7.norm2: LayerNorm\n",
            "  backbone.encoder.layer.7.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.7.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.7.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.7.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.7.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.8: Dinov2Layer\n",
            "  backbone.encoder.layer.8.norm1: LayerNorm\n",
            "  backbone.encoder.layer.8.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.8.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.8.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.8.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.8.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.8.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.8.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.8.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.8.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.8.drop_path: Identity\n",
            "  backbone.encoder.layer.8.norm2: LayerNorm\n",
            "  backbone.encoder.layer.8.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.8.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.8.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.8.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.8.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.9: Dinov2Layer\n",
            "  backbone.encoder.layer.9.norm1: LayerNorm\n",
            "  backbone.encoder.layer.9.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.9.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.9.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.9.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.9.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.9.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.9.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.9.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.9.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.9.drop_path: Identity\n",
            "  backbone.encoder.layer.9.norm2: LayerNorm\n",
            "  backbone.encoder.layer.9.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.9.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.9.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.9.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.9.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.10: Dinov2Layer\n",
            "  backbone.encoder.layer.10.norm1: LayerNorm\n",
            "  backbone.encoder.layer.10.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.10.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.10.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.10.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.10.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.10.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.10.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.10.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.10.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.10.drop_path: Identity\n",
            "  backbone.encoder.layer.10.norm2: LayerNorm\n",
            "  backbone.encoder.layer.10.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.10.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.10.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.10.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.10.layer_scale2: Dinov2LayerScale\n",
            "  backbone.encoder.layer.11: Dinov2Layer\n",
            "  backbone.encoder.layer.11.norm1: LayerNorm\n",
            "  backbone.encoder.layer.11.attention: Dinov2Attention\n",
            "  backbone.encoder.layer.11.attention.attention: Dinov2SelfAttention\n",
            "  backbone.encoder.layer.11.attention.attention.query: Linear\n",
            "  backbone.encoder.layer.11.attention.attention.key: Linear\n",
            "  backbone.encoder.layer.11.attention.attention.value: Linear\n",
            "  backbone.encoder.layer.11.attention.output: Dinov2SelfOutput\n",
            "  backbone.encoder.layer.11.attention.output.dense: Linear\n",
            "  backbone.encoder.layer.11.attention.output.dropout: Dropout\n",
            "  backbone.encoder.layer.11.layer_scale1: Dinov2LayerScale\n",
            "  backbone.encoder.layer.11.drop_path: Identity\n",
            "  backbone.encoder.layer.11.norm2: LayerNorm\n",
            "  backbone.encoder.layer.11.mlp: Dinov2MLP\n",
            "  backbone.encoder.layer.11.mlp.fc1: Linear\n",
            "  backbone.encoder.layer.11.mlp.activation: GELUActivation\n",
            "  backbone.encoder.layer.11.mlp.fc2: Linear\n",
            "  backbone.encoder.layer.11.layer_scale2: Dinov2LayerScale\n",
            "  backbone.layernorm: LayerNorm\n",
            "  neck: DepthAnythingNeck\n",
            "  neck.reassemble_stage: DepthAnythingReassembleStage\n",
            "  neck.reassemble_stage.layers: ModuleList\n",
            "  neck.reassemble_stage.layers.0: DepthAnythingReassembleLayer\n",
            "  neck.reassemble_stage.layers.0.projection: Conv2d\n",
            "  neck.reassemble_stage.layers.0.resize: ConvTranspose2d\n",
            "  neck.reassemble_stage.layers.1: DepthAnythingReassembleLayer\n",
            "  neck.reassemble_stage.layers.1.projection: Conv2d\n",
            "  neck.reassemble_stage.layers.1.resize: ConvTranspose2d\n",
            "  neck.reassemble_stage.layers.2: DepthAnythingReassembleLayer\n",
            "  neck.reassemble_stage.layers.2.projection: Conv2d\n",
            "  neck.reassemble_stage.layers.2.resize: Identity\n",
            "  neck.reassemble_stage.layers.3: DepthAnythingReassembleLayer\n",
            "  neck.reassemble_stage.layers.3.projection: Conv2d\n",
            "  neck.reassemble_stage.layers.3.resize: Conv2d\n",
            "  neck.convs: ModuleList\n",
            "  neck.convs.0: Conv2d\n",
            "  neck.convs.1: Conv2d\n",
            "  neck.convs.2: Conv2d\n",
            "  neck.convs.3: Conv2d\n",
            "  neck.fusion_stage: DepthAnythingFeatureFusionStage\n",
            "  neck.fusion_stage.layers: ModuleList\n",
            "  neck.fusion_stage.layers.0: DepthAnythingFeatureFusionLayer\n",
            "  neck.fusion_stage.layers.0.projection: Conv2d\n",
            "  neck.fusion_stage.layers.0.residual_layer1: DepthAnythingPreActResidualLayer\n",
            "  neck.fusion_stage.layers.0.residual_layer1.activation1: ReLU\n",
            "  neck.fusion_stage.layers.0.residual_layer1.convolution1: Conv2d\n",
            "  neck.fusion_stage.layers.0.residual_layer1.activation2: ReLU\n",
            "  neck.fusion_stage.layers.0.residual_layer1.convolution2: Conv2d\n",
            "  neck.fusion_stage.layers.0.residual_layer2: DepthAnythingPreActResidualLayer\n",
            "  neck.fusion_stage.layers.0.residual_layer2.activation1: ReLU\n",
            "  neck.fusion_stage.layers.0.residual_layer2.convolution1: Conv2d\n",
            "  neck.fusion_stage.layers.0.residual_layer2.activation2: ReLU\n",
            "  neck.fusion_stage.layers.0.residual_layer2.convolution2: Conv2d\n",
            "  neck.fusion_stage.layers.1: DepthAnythingFeatureFusionLayer\n",
            "  neck.fusion_stage.layers.1.projection: Conv2d\n",
            "  neck.fusion_stage.layers.1.residual_layer1: DepthAnythingPreActResidualLayer\n",
            "  neck.fusion_stage.layers.1.residual_layer1.activation1: ReLU\n",
            "  neck.fusion_stage.layers.1.residual_layer1.convolution1: Conv2d\n",
            "  neck.fusion_stage.layers.1.residual_layer1.activation2: ReLU\n",
            "  neck.fusion_stage.layers.1.residual_layer1.convolution2: Conv2d\n",
            "  neck.fusion_stage.layers.1.residual_layer2: DepthAnythingPreActResidualLayer\n",
            "  neck.fusion_stage.layers.1.residual_layer2.activation1: ReLU\n",
            "  neck.fusion_stage.layers.1.residual_layer2.convolution1: Conv2d\n",
            "  neck.fusion_stage.layers.1.residual_layer2.activation2: ReLU\n",
            "  neck.fusion_stage.layers.1.residual_layer2.convolution2: Conv2d\n",
            "  neck.fusion_stage.layers.2: DepthAnythingFeatureFusionLayer\n",
            "  neck.fusion_stage.layers.2.projection: Conv2d\n",
            "  neck.fusion_stage.layers.2.residual_layer1: DepthAnythingPreActResidualLayer\n",
            "  neck.fusion_stage.layers.2.residual_layer1.activation1: ReLU\n",
            "  neck.fusion_stage.layers.2.residual_layer1.convolution1: Conv2d\n",
            "  neck.fusion_stage.layers.2.residual_layer1.activation2: ReLU\n",
            "  neck.fusion_stage.layers.2.residual_layer1.convolution2: Conv2d\n",
            "  neck.fusion_stage.layers.2.residual_layer2: DepthAnythingPreActResidualLayer\n",
            "  neck.fusion_stage.layers.2.residual_layer2.activation1: ReLU\n",
            "  neck.fusion_stage.layers.2.residual_layer2.convolution1: Conv2d\n",
            "  neck.fusion_stage.layers.2.residual_layer2.activation2: ReLU\n",
            "  neck.fusion_stage.layers.2.residual_layer2.convolution2: Conv2d\n",
            "  neck.fusion_stage.layers.3: DepthAnythingFeatureFusionLayer\n",
            "  neck.fusion_stage.layers.3.projection: Conv2d\n",
            "  neck.fusion_stage.layers.3.residual_layer1: DepthAnythingPreActResidualLayer\n",
            "  neck.fusion_stage.layers.3.residual_layer1.activation1: ReLU\n",
            "  neck.fusion_stage.layers.3.residual_layer1.convolution1: Conv2d\n",
            "  neck.fusion_stage.layers.3.residual_layer1.activation2: ReLU\n",
            "  neck.fusion_stage.layers.3.residual_layer1.convolution2: Conv2d\n",
            "  neck.fusion_stage.layers.3.residual_layer2: DepthAnythingPreActResidualLayer\n",
            "  neck.fusion_stage.layers.3.residual_layer2.activation1: ReLU\n",
            "  neck.fusion_stage.layers.3.residual_layer2.convolution1: Conv2d\n",
            "  neck.fusion_stage.layers.3.residual_layer2.activation2: ReLU\n",
            "  neck.fusion_stage.layers.3.residual_layer2.convolution2: Conv2d\n",
            "  head: DepthAnythingDepthEstimationHead\n",
            "  head.conv1: Conv2d\n",
            "  head.conv2: Conv2d\n",
            "  head.activation1: ReLU\n",
            "  head.conv3: Conv2d\n",
            "  head.activation2: ReLU\n",
            "\n",
            "============================================================\n",
            "TRAINABLE LAYERS (before LoRA):\n",
            "  backbone.embeddings.cls_token: torch.Size([1, 1, 384])\n",
            "  backbone.embeddings.mask_token: torch.Size([1, 384])\n",
            "  backbone.embeddings.position_embeddings: torch.Size([1, 1370, 384])\n",
            "  backbone.embeddings.patch_embeddings.projection.weight: torch.Size([384, 3, 14, 14])\n",
            "  backbone.embeddings.patch_embeddings.projection.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.0.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.0.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.0.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.0.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.0.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.0.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.0.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.0.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.0.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.0.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.0.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.0.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.0.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.0.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.0.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.0.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.0.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.0.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.1.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.1.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.1.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.1.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.1.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.1.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.1.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.1.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.1.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.1.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.1.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.1.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.1.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.1.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.1.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.1.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.1.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.1.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.2.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.2.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.2.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.2.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.2.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.2.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.2.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.2.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.2.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.2.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.2.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.2.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.2.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.2.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.2.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.2.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.2.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.2.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.3.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.3.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.3.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.3.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.3.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.3.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.3.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.3.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.3.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.3.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.3.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.3.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.3.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.3.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.3.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.3.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.3.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.3.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.4.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.4.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.4.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.4.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.4.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.4.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.4.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.4.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.4.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.4.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.4.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.4.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.4.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.4.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.4.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.4.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.4.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.4.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.5.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.5.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.5.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.5.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.5.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.5.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.5.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.5.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.5.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.5.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.5.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.5.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.5.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.5.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.5.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.5.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.5.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.5.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.6.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.6.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.6.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.6.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.6.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.6.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.6.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.6.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.6.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.6.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.6.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.6.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.6.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.6.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.6.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.6.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.6.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.6.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.7.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.7.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.7.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.7.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.7.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.7.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.7.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.7.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.7.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.7.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.7.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.7.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.7.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.7.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.7.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.7.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.7.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.7.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.8.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.8.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.8.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.8.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.8.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.8.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.8.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.8.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.8.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.8.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.8.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.8.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.8.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.8.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.8.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.8.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.8.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.8.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.9.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.9.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.9.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.9.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.9.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.9.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.9.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.9.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.9.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.9.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.9.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.9.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.9.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.9.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.9.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.9.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.9.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.9.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.10.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.10.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.10.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.10.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.10.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.10.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.10.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.10.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.10.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.10.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.10.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.10.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.10.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.10.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.10.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.10.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.10.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.10.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.11.norm1.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.11.norm1.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.11.attention.attention.query.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.11.attention.attention.query.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.11.attention.attention.key.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.11.attention.attention.key.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.11.attention.attention.value.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.11.attention.attention.value.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.11.attention.output.dense.weight: torch.Size([384, 384])\n",
            "  backbone.encoder.layer.11.attention.output.dense.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.11.layer_scale1.lambda1: torch.Size([384])\n",
            "  backbone.encoder.layer.11.norm2.weight: torch.Size([384])\n",
            "  backbone.encoder.layer.11.norm2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.11.mlp.fc1.weight: torch.Size([1536, 384])\n",
            "  backbone.encoder.layer.11.mlp.fc1.bias: torch.Size([1536])\n",
            "  backbone.encoder.layer.11.mlp.fc2.weight: torch.Size([384, 1536])\n",
            "  backbone.encoder.layer.11.mlp.fc2.bias: torch.Size([384])\n",
            "  backbone.encoder.layer.11.layer_scale2.lambda1: torch.Size([384])\n",
            "  backbone.layernorm.weight: torch.Size([384])\n",
            "  backbone.layernorm.bias: torch.Size([384])\n",
            "  neck.reassemble_stage.layers.0.projection.weight: torch.Size([48, 384, 1, 1])\n",
            "  neck.reassemble_stage.layers.0.projection.bias: torch.Size([48])\n",
            "  neck.reassemble_stage.layers.0.resize.weight: torch.Size([48, 48, 4, 4])\n",
            "  neck.reassemble_stage.layers.0.resize.bias: torch.Size([48])\n",
            "  neck.reassemble_stage.layers.1.projection.weight: torch.Size([96, 384, 1, 1])\n",
            "  neck.reassemble_stage.layers.1.projection.bias: torch.Size([96])\n",
            "  neck.reassemble_stage.layers.1.resize.weight: torch.Size([96, 96, 2, 2])\n",
            "  neck.reassemble_stage.layers.1.resize.bias: torch.Size([96])\n",
            "  neck.reassemble_stage.layers.2.projection.weight: torch.Size([192, 384, 1, 1])\n",
            "  neck.reassemble_stage.layers.2.projection.bias: torch.Size([192])\n",
            "  neck.reassemble_stage.layers.3.projection.weight: torch.Size([384, 384, 1, 1])\n",
            "  neck.reassemble_stage.layers.3.projection.bias: torch.Size([384])\n",
            "  neck.reassemble_stage.layers.3.resize.weight: torch.Size([384, 384, 3, 3])\n",
            "  neck.reassemble_stage.layers.3.resize.bias: torch.Size([384])\n",
            "  neck.convs.0.weight: torch.Size([64, 48, 3, 3])\n",
            "  neck.convs.1.weight: torch.Size([64, 96, 3, 3])\n",
            "  neck.convs.2.weight: torch.Size([64, 192, 3, 3])\n",
            "  neck.convs.3.weight: torch.Size([64, 384, 3, 3])\n",
            "  neck.fusion_stage.layers.0.projection.weight: torch.Size([64, 64, 1, 1])\n",
            "  neck.fusion_stage.layers.0.projection.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.0.residual_layer1.convolution1.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.0.residual_layer1.convolution1.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.0.residual_layer1.convolution2.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.0.residual_layer1.convolution2.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.0.residual_layer2.convolution1.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.0.residual_layer2.convolution1.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.0.residual_layer2.convolution2.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.0.residual_layer2.convolution2.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.1.projection.weight: torch.Size([64, 64, 1, 1])\n",
            "  neck.fusion_stage.layers.1.projection.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.1.residual_layer1.convolution1.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.1.residual_layer1.convolution1.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.1.residual_layer1.convolution2.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.1.residual_layer1.convolution2.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.1.residual_layer2.convolution1.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.1.residual_layer2.convolution1.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.1.residual_layer2.convolution2.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.1.residual_layer2.convolution2.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.2.projection.weight: torch.Size([64, 64, 1, 1])\n",
            "  neck.fusion_stage.layers.2.projection.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.2.residual_layer1.convolution1.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.2.residual_layer1.convolution1.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.2.residual_layer1.convolution2.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.2.residual_layer1.convolution2.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.2.residual_layer2.convolution1.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.2.residual_layer2.convolution1.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.2.residual_layer2.convolution2.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.2.residual_layer2.convolution2.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.3.projection.weight: torch.Size([64, 64, 1, 1])\n",
            "  neck.fusion_stage.layers.3.projection.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.3.residual_layer1.convolution1.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.3.residual_layer1.convolution1.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.3.residual_layer1.convolution2.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.3.residual_layer1.convolution2.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.3.residual_layer2.convolution1.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.3.residual_layer2.convolution1.bias: torch.Size([64])\n",
            "  neck.fusion_stage.layers.3.residual_layer2.convolution2.weight: torch.Size([64, 64, 3, 3])\n",
            "  neck.fusion_stage.layers.3.residual_layer2.convolution2.bias: torch.Size([64])\n",
            "  head.conv1.weight: torch.Size([32, 64, 3, 3])\n",
            "  head.conv1.bias: torch.Size([32])\n",
            "  head.conv2.weight: torch.Size([32, 32, 3, 3])\n",
            "  head.conv2.bias: torch.Size([32])\n",
            "  head.conv3.weight: torch.Size([1, 32, 1, 1])\n",
            "  head.conv3.bias: torch.Size([1])\n"
          ]
        }
      ],
      "source": [
        "# ===================================================\n",
        "# INSPECT MODEL ARCHITECTURE\n",
        "# ===================================================\n",
        "print(\"üîç Inspecting model architecture...\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Print all module names\n",
        "print(\"MODEL STRUCTURE:\")\n",
        "for name, module in base_model.named_modules():\n",
        "    print(f\"  {name}: {module.__class__.__name__}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINABLE LAYERS (before LoRA):\")\n",
        "for name, param in base_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"  {name}: {param.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy66WTOwgAVY"
      },
      "source": [
        "PREPARATION  des donn√©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "path_images = r\"P:\\images\"\n",
        "path_depths = r\"P:\\depth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Dossier Images vis√© : P:\\images\n",
            "üìÇ Dossier Depth vis√©  : P:\\depth\n",
            "\n",
            "‚úÖ Les dossiers existent !\n",
            "   -> Trouv√© 58 images\n",
            "   -> Trouv√© 58 fichiers XYZ (.npy)\n"
          ]
        }
      ],
      "source": [
        "print(f\"üìÇ Dossier Images vis√© : {path_images}\")\n",
        "print(f\"üìÇ Dossier Depth vis√©  : {path_depths}\")\n",
        "\n",
        "# V√©rification que les dossiers existent\n",
        "if os.path.exists(path_images) and os.path.exists(path_depths):\n",
        "    print(\"\\n‚úÖ Les dossiers existent !\")\n",
        "    \n",
        "    # Compter les fichiers pour √™tre s√ªr\n",
        "    nb_img = len([f for f in os.listdir(path_images) if f.endswith(('.png', '.jpg'))])\n",
        "    nb_npy = len([f for f in os.listdir(path_depths) if f.endswith('.npy')])\n",
        "    \n",
        "    print(f\"   -> Trouv√© {nb_img} images\")\n",
        "    print(f\"   -> Trouv√© {nb_npy} fichiers XYZ (.npy)\")\n",
        "else:\n",
        "    print(\"\\n‚ùå ERREUR : Un des chemins est introuvable.\")\n",
        "    print(\"   V√©rifie l'orthographe ou copie le chemin absolu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç D√©marrage de la v√©rification...\n",
            "üìä Bilan comptable :\n",
            "   - Images (.png/.jpg) : 58\n",
            "   - Depths (.npy)      : 58\n"
          ]
        }
      ],
      "source": [
        "# 2. COMPTAGE ET LISTING\n",
        "# ==========================================\n",
        "print(\"üîç D√©marrage de la v√©rification...\")\n",
        "\n",
        "# On liste et on trie pour garantir l'ordre\n",
        "# On ne garde que les fichiers (pas les dossiers cach√©s)\n",
        "files_img = sorted([f for f in os.listdir(path_images) if f.endswith(('.png', '.jpg'))])\n",
        "files_npy = sorted([f for f in os.listdir(path_depths) if f.endswith('.npy')])\n",
        "\n",
        "num_img = len(files_img)\n",
        "num_npy = len(files_npy)\n",
        "\n",
        "print(f\"üìä Bilan comptable :\")\n",
        "print(f\"   - Images (.png/.jpg) : {num_img}\")\n",
        "print(f\"   - Depths (.npy)      : {num_npy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Le nombre de fichiers est identique.\n",
            "‚úÖ Tous les noms de fichiers semblent correspondre (logique color <-> rawDepth).\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 3. V√âRIFICATION DE L'ALIGNEMENT\n",
        "# ==========================================\n",
        "if num_img != num_npy:\n",
        "    print(f\"‚ùå ATTENTION : Le nombre de fichiers ne correspond pas ! (Diff√©rence : {abs(num_img - num_npy)})\")\n",
        "else:\n",
        "    print(\"‚úÖ Le nombre de fichiers est identique.\")\n",
        "\n",
        "# V√©rification des correspondances de noms (optionnel mais recommand√©)\n",
        "# On v√©rifie si image_01_color.png a bien son √©quivalent image_01_rawDepth.npy\n",
        "mismatches = []\n",
        "for img_name in files_img:\n",
        "    # On recr√©e le nom attendu du fichier depth (selon la logique Zivid vue dans ton notebook)\n",
        "    # Ex: \"scan_color.png\" -> \"scan_rawDepth.npy\"\n",
        "    expected_depth_name = img_name.replace(\"_color.png\", \"_rawDepth.npy\").replace(\".png\", \".npy\")\n",
        "    \n",
        "    # Si tes fichiers n'ont pas \"_color\", ajuste cette ligne (ex: replace(\".png\", \".npy\"))\n",
        "    \n",
        "    if expected_depth_name not in files_npy:\n",
        "        mismatches.append((img_name, expected_depth_name))\n",
        "\n",
        "if len(mismatches) > 0:\n",
        "    print(f\"‚ö†Ô∏è ATTENTION : {len(mismatches)} paires ne correspondent pas au niveau du nom !\")\n",
        "    print(f\"   Exemple de manquant : {mismatches[0]}\")\n",
        "else:\n",
        "    print(\"‚úÖ Tous les noms de fichiers semblent correspondre (logique color <-> rawDepth).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üß™ Test d'extraction du canal Z sur un fichier al√©atoire...\n",
            "   Fichier : 21-12-03-19-05-46_Zivid_acquisition_rawDepth.npy\n",
            "   Shape originale : (1200, 1944, 3)\n",
            "   ‚úÖ Extraction Z r√©ussie ! Shape finale : (1200, 1944)\n",
            "   Val Min (avec NaN) : 851.3021240234375\n",
            "   Val Max (avec NaN) : 2249.957275390625\n",
            "   Nombre de pixels NaN (vides) : 652630 (28.0%)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 4. TEST D'EXTRACTION DU Z (Le fameux Z)\n",
        "# ==========================================\n",
        "\n",
        "if num_npy > 0:\n",
        "    print(\"\\nüß™ Test d'extraction du canal Z sur un fichier al√©atoire...\")\n",
        "    \n",
        "    # Prendre un fichier au hasard\n",
        "    random_npy = random.choice(files_npy)\n",
        "    full_path = os.path.join(path_depths, random_npy)\n",
        "    \n",
        "    try:\n",
        "        # Chargement\n",
        "        data = np.load(full_path) # Shape (H, W, 3) normalement\n",
        "        \n",
        "        print(f\"   Fichier : {random_npy}\")\n",
        "        print(f\"   Shape originale : {data.shape}\")\n",
        "        \n",
        "        if len(data.shape) == 3 and data.shape[2] == 3:\n",
        "            # EXTRACTION DU Z (Canal index 2)\n",
        "            Z_channel = data[:, :, 2]\n",
        "            \n",
        "            # V√©rif statistiques\n",
        "            print(f\"   ‚úÖ Extraction Z r√©ussie ! Shape finale : {Z_channel.shape}\")\n",
        "            print(f\"   Val Min (avec NaN) : {np.nanmin(Z_channel)}\")\n",
        "            print(f\"   Val Max (avec NaN) : {np.nanmax(Z_channel)}\")\n",
        "            \n",
        "            # V√©rification des NaN\n",
        "            nan_count = np.isnan(Z_channel).sum()\n",
        "            print(f\"   Nombre de pixels NaN (vides) : {nan_count} ({(nan_count/Z_channel.size)*100:.1f}%)\")\n",
        "        else:\n",
        "            print(\"‚ùå Erreur : Le fichier .npy n'a pas 3 canaux (XYZ). V√©rifie le format.\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur lors du chargement : {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Le fichier charg√© est de forme : (1200, 1944)\n",
            "La valeur de Profondeur (Z) au pixel [600, 972] est :\n",
            "-> **1365.02 mm**\n"
          ]
        }
      ],
      "source": [
        "filename = \"21-12-03-19-05-46_Zivid_acquisition_rawDepth.npy\"\n",
        "full_path = os.path.join(path_depths, filename)\n",
        "\n",
        "# --- EXTRACTION ---\n",
        "# 1. Chargement de la donn√©e (1200, 1944, 3)\n",
        "data_xyz = np.load(full_path)\n",
        "\n",
        "# 2. Extraction de la carte de profondeur Z (1200, 1944)\n",
        "Z_channel = data_xyz[:, :, 2] \n",
        "\n",
        "# 3. Traitement des NaN (pour s'assurer qu'on peut lire)\n",
        "Z_clean = np.nan_to_num(Z_channel, nan=0.0)\n",
        "\n",
        "# --- LECTURE DE LA VALEUR D'UN PIXEL ---\n",
        "pixel_row = 600\n",
        "pixel_col = 972\n",
        "\n",
        "# Acc√©der √† la valeur Z du pixel (600, 972)\n",
        "profondeur_pixel = Z_clean[pixel_row, pixel_col]\n",
        "\n",
        "print(f\"Le fichier charg√© est de forme : {Z_channel.shape}\")\n",
        "print(f\"La valeur de Profondeur (Z) au pixel [{pixel_row}, {pixel_col}] est :\")\n",
        "print(f\"-> **{profondeur_pixel:.2f} mm**\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "076e2ab7dedf4ed8b75a60f1f3a4c182": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a2389a8e9474a1c954fea1ef57ff827",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_309e815f91bf4a5e903514e9ae19cf4b",
            "value": "‚Äá950/950‚Äá[00:00&lt;00:00,‚Äá54.3kB/s]"
          }
        },
        "0c6eba7aa7de4611b9176572cb53b7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "157d607e7a5d4ddd9ba3d89812e33617": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f42814e26745dbbfdbe1ac5cf57298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63377198212c4fab8098723b7cd6915d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8233d752f5e54588b9f565c34d1efd24",
            "value": "‚Äá99.2M/99.2M‚Äá[00:02&lt;00:00,‚Äá53.1MB/s]"
          }
        },
        "1e58d3730b684917b3be89d38cd28ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48fed41b86484cc69e97afd7201b3f1d",
              "IPY_MODEL_836a5991140b4555af8547aff5249c35",
              "IPY_MODEL_fb78ae1d82fa4cb491d18cb4deb7c1df"
            ],
            "layout": "IPY_MODEL_7734292198df4e0e9800bccaa2df8fa6"
          }
        },
        "22ba49dd0e2d44ab87ca48ba3c1c2694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef818123e294b4bbeb1a0b02fa9165d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_26a5af69e89f449abf359097bd213a83",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "26a5af69e89f449abf359097bd213a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a2389a8e9474a1c954fea1ef57ff827": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "309e815f91bf4a5e903514e9ae19cf4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "383b0a4ac06f44a8a02dea81a6eb8967": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48fed41b86484cc69e97afd7201b3f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f848dfbe32b4328a8995eae51747ef5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ee145691058c46708dd70c8e82c4659b",
            "value": "preprocessor_config.json:‚Äá100%"
          }
        },
        "4e5148adce63409bad335d560b48c469": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5aa91a828b5d457b86a960116ee87ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ffa3f78d94940a09d39d879db31afa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_383b0a4ac06f44a8a02dea81a6eb8967",
            "max": 99173660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c6eba7aa7de4611b9176572cb53b7fe",
            "value": 99173660
          }
        },
        "607f56a23c4a4d258a44568d80d8b6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63377198212c4fab8098723b7cd6915d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a2beca0ae69432290746120f97d8d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70f8d58533414a13b0d24e5baf4d801b",
            "max": 950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7300f79f002b45a59b181c4f3b89b604",
            "value": 950
          }
        },
        "70f8d58533414a13b0d24e5baf4d801b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71dd44e393084109951e526ddae89efb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7300f79f002b45a59b181c4f3b89b604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7734292198df4e0e9800bccaa2df8fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f848dfbe32b4328a8995eae51747ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8233d752f5e54588b9f565c34d1efd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "836a5991140b4555af8547aff5249c35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92c720ebd5d340d18a85951dbd0caa26",
            "max": 775,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_607f56a23c4a4d258a44568d80d8b6e0",
            "value": 775
          }
        },
        "85960be4e08a418daff7764b81cfc1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e1b9eba1ce40c789fee7d975e6d808": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c720ebd5d340d18a85951dbd0caa26": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c7361241d642aba28db4583568a43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_157d607e7a5d4ddd9ba3d89812e33617",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5aa91a828b5d457b86a960116ee87ccf",
            "value": "config.json:‚Äá100%"
          }
        },
        "cef818123e294b4bbeb1a0b02fa9165d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc130e6335c0479c9a14f58346264929": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22ba49dd0e2d44ab87ca48ba3c1c2694",
              "IPY_MODEL_5ffa3f78d94940a09d39d879db31afa0",
              "IPY_MODEL_18f42814e26745dbbfdbe1ac5cf57298"
            ],
            "layout": "IPY_MODEL_71dd44e393084109951e526ddae89efb"
          }
        },
        "ee145691058c46708dd70c8e82c4659b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee3e596dd0bc409eb1881ae126249055": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8c7361241d642aba28db4583568a43d",
              "IPY_MODEL_6a2beca0ae69432290746120f97d8d9d",
              "IPY_MODEL_076e2ab7dedf4ed8b75a60f1f3a4c182"
            ],
            "layout": "IPY_MODEL_85960be4e08a418daff7764b81cfc1a5"
          }
        },
        "fb78ae1d82fa4cb491d18cb4deb7c1df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e1b9eba1ce40c789fee7d975e6d808",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4e5148adce63409bad335d560b48c469",
            "value": "‚Äá775/775‚Äá[00:00&lt;00:00,‚Äá36.4kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
